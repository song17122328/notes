### 感知机总结

* 感知机是一个二分类的问题，是最早的AI模型之一
* 它的求解算法等于与使用批量大小为1的梯队下降
* 它不能拟合XOR函数，导致了第一次AI函数(XOR函数的最终被多层感知机解决)

### 多层感知机总结

* 多层感知机通过增加了隐藏层和激活函数解决了XOR问题。
* 多层感知机从理论上可以拟合任何函数，但实际参数优化会较为困难。
* 多层感知机有很多激活函数，这些激活函数没有本质的区别，只是增强非线性。因此ReLU函数可能更常用，因为ReLU函数更简单，计算效率更高。像sigmoid函数，tanh函数等计算梯度要昂贵的多。
* 在实际的经验中，多用几层数隐藏层使得模型更深，神经单元数量逐渐变少，效果可能会好于使用一层非常宽的隐藏层。

更瘦长效果比更宽短的模型要好，但在理论上两者一样(或者是能证明瘦长的模型效果更好的理论还没有出现)。一些人认为这是因为多层隐藏层可以学到输入数学不同的特征，比如输入一张动物图片，一层学到耳朵，一层学到眼睛之类的。而宽大的隐藏层可能对所有参数的协同要求更好，调参上更难。

### 模型训练

训练误差：模型在训练数据上的误差

泛化误差：模型在新数据上的误差

训练数据集：训练模型参数

验证数据集：一个用来评估模型好坏的数据集，可以用来评价超参数的好坏（选择模型超参数）

* 例如拿出50%的训练数据
* 不要跟训练数据混在一起(常犯错误)

测试数据集：只用一次的数据集。例如：

* 未来的考试
* 我出价的房子实际成交价
* 用在Kaggle私有排行榜中的数据集

K-则交叉验证

* 在没有足够多数据时使用（经常用到）
* 算法：
  * 将训练数据分割成K块
  * For i=1，……，K
    * 使用第i块作为验证数据集，其余作为训练数据集
  * 报告K个验证集误差的平均
* 常用：K=5或10

### 过拟合和欠拟合

| 模型容量\数据 | 简单   | 复杂   |
| ------------- | ------ | ------ |
| 低            | 正常   | 欠拟合 |
| 高            | 过拟合 | 正常   |

模型容量：

* 拟合各种函数的能力
* 低容量的模型难以拟合训练数据
* 高容量的模型可以记住所有训练数据

![模型复杂度对欠拟合和过拟合的影响](https://s3.bmp.ovh/imgs/2025/04/11/c4e5a4b322ea856c.png)