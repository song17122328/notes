### 一、线性回归

* 线性模型可以看作一层的神经网络
* 线性回归是对n维输入的加权，外加偏差
* 线性回归使用平方损失来衡量预测值和真实值的差异，损失函数是凸函数，有显式解(精确解)

### 二、基础优化算法

##### **1、学习率和Batch_size**：

学习率不能太大也不能太小，学习率太小会导致收敛很慢，消耗计算资源；学习率太大可能会导致跳过收敛点，也不合适。

由于计算梯度比较昂贵，直接对所有数据进行损失梯度下降计算非常昂贵，从所有数据中选择一部分计算损失，以代表总体的损失，这一部分数据的规模叫做批量大小，批量大小就是代替总体的样本大小。

在选取批量大小上，不能太小，太小不适合并行无法最大利用计算资源；也不适合太大，太大内存消耗增加浪费资源。

总结：

* 梯度下降通过不断沿着反梯度方向更新参数求解
* 小批量随即梯度下降是深度学习默认的求解算法
* 两个重要的超参数是批量大小和学习率

##### 2、深刻认识随机梯度下降算法

通过类比牛顿法和随机梯度下降(SGD: stochastic gradient descent ) 来**深刻认识神经网络和随机梯度下降算法**。

在数学理论上牛顿法可能更优，但在神经网络中进行参数调优仍通常使用随机梯度下降（SGD: stochastic gradient descent）法。

其原理是牛顿法利用到损失函数的二阶导数(Hessian矩阵)信息，直接跳到二次近似最小值。而随机梯度下降法沿着一阶导数下降最快的方向以合适的学习率不断迭代寻找使得损失函数最小的参数最优解。因此从理论上牛顿法要快于随机梯度下降(stochastic gradient descent)。但在具体实践过程中，几乎不使用牛顿法，以下是几点原因：

* 牛顿法寻找最优解最适合损失函数是凸函数的情况，但实践中损失函数可能异常复杂，极少存在凸函数的损失函数(这是因为神经网络常常处理NP-complete问题，无法找到精确解)，牛顿法在非凸函数中很可能收敛在鞍点，而非极值点。
* 在具体实践过程中，数据量很可能异常庞大，我们知道损失函数是标量，其一阶导数是向量，二阶导是矩阵。牛顿法要用到Hessian矩阵和Hessian矩阵的逆矩阵，需要求二阶导和二阶导的逆，对内存的消耗达到O(n^2)甚至O（n^3）的程度，这对大规模数据量训练是不可接受的。

使用随机梯度下降法的原因：

* 随机梯度下降法使用迭代收敛的方式，每次只取一个小批次(Batch)，内存消耗少，非常适合大数据集。
* 使用小批次(Batch)进行参数调优，而非计算二阶Hessian矩阵，有利于充分利用GPU的并行计算功能，提高资源利用率。
* 随机梯度下降中利用到随机，有助于跳出局部最优解。
* 随机梯度下降中的随机其实给数据带来的噪声，在高纬度深层次的神经网络训练中，有利于提高模型对噪声的抗干扰能力，提高模型的鲁棒性和泛化性能，避免过拟合。

### 三、softmax回归

softmax回归其实是一个分类问题。回归的输出是一个符合自然区间的数值，损失函数是预测值和真实值的差距。分类通常有多个输出，**第i个输出是预测为第i类的置信度**。

* 回归是单输出，分类是多输出（soft regression其实是分类）

##### 1、模型输出分析

神经网络输出为 $\mathbf{o} = \mathbf{W} \mathbf{x} + \mathbf{b}$，W是参数，x是特征，b为偏置值；

模型预测输出为 $\mathbf{\hat{y}} = \underset i {\mathrm{argmax}} \, \mathbf{o_i}$ 其中 $o_i$ 为输出层第i个神经单元的输出 ，$\hat{y}$ 为预测值。

在识别过程中，我们希望对正确类的置信度要远远大于其他类，因此 $O_y - O_i \ge \Delta(y,i)$

为了令神经网络输出成为一个概率，使用softmax算子(softmax函数)对所有输出神经元进行激活，得到模型输出
$$
\hat{\mathbf{y}} = \mathrm{softmax}(\mathbf{o})\quad \text{其中}\quad \mathbf{\hat{y}_j} = \frac{\exp(o_j)}{\sum_k \exp(o_k)}
$$
通过比较预测值 $\hat{y}$ 和真实值 $y$ 之间的区别作为损失。选择交叉熵来衡量 $\hat{y} 与 y$ 的区别。因此损失函数为交叉熵损失。

##### 2、深入理解交叉熵损失

**（1）使用交叉熵损失，不适用MSE的原因**

在 **Softmax回归**（多类逻辑回归）中，使用 **交叉熵损失（Cross-Entropy Loss）** 而非 **均方误差（MSE）** 作为损失函数。

* **模型输出不匹配**

softmax输出结果是概率分布，MSE适用输出结果是任意实数值且MSE对概率的惩罚过于平均：$真实标签 y=[0,0,1]（第三类），模型预测 \hat{y}=[0.1,0.1,0.8] 和 \hat{y}=[0.4,0.4,0.2]的MSE可能相近，但后者完全分类错误$

* **梯度优化困难**

交叉熵的梯度是 $\hat{y}-y$，与误差成比例，而MSE的梯度是 $(\hat{y}-y)*\hat{y}*(1-\hat{y})$.多了$\hat{y}*(1-\hat{y})$.当预测概率接近1时候，多出的项接近于0，导致梯度消失，因此在训练后期MSE收敛速度要比交叉熵损失慢得多。

* **错误预测敏感不足**

分类任务的目标函数是追求预测正确的概率最大，预测错误的概率尽可能小，因此需要损失函数的惩罚不能过于平均，交叉熵对正确率的预测低概率惩罚很大 -log(pi)，更符合要求。

**（2）为什么不用KL散度（KLD）？**

在分类任务中cross Entropy 和KLD等价，本质都是衡量两个概率分布之间的差异，但是KL散度计算更复杂。KL散度与Cross Entropy与信息熵的关系：
$$
D_{KL}(P∥Q)=H(P,Q)−H(P)
$$

$$
H ( P )=-\sum_{x} P ( x ) \operatorname{l o g} P ( x )
\newline
D_{K L} ( P \| Q )=\sum_{x} P ( x ) \operatorname{l o g} \frac{P ( x )} {Q ( x )} 
\newline

H ( P, Q )=H ( P )+D_{K L} ( P \| Q )=-\sum_{x} P ( x ) \operatorname{l o g} Q ( x )
$$

在分类任务中，实际概率分布P为one-hot编码，如[0, 1 ,0, 0]，$H(P)$为0.

| 角度           | 交叉熵（Cross-Entropy）                         | KL散度（KLD）                         |
| :------------- | :---------------------------------------------- | :------------------------------------ |
| **数学等价性** | 在分类任务中与KL散度等价（因 H(P)=0*H*(*P*)=0） | 需额外计算 H(P)*H*(*P*)，但实际无意义 |
| **计算效率**   | 更简洁，框架直接支持                            | 需组合交叉熵和熵                      |
| **梯度优化**   | 与KL散度完全一致                                | 相同                                  |
| **适用场景**   | 分类任务（one-hot标签）                         | 生成模型、非one-hot分布（如知识蒸馏） |

$$

$$



