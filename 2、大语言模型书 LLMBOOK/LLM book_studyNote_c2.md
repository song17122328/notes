

**重点知识前览：**

大语言模型：是指在**海量无标注文本**数据上进行**预训练**得到的大型预训练语言模型(如GPT-3,PaLM,LLaMA)

预训练定义：预训练是指使用与下游任务无关的大规模数据进行模型参数的初始训练，可以认为是为模型参数找到一个较好的“**初值点**”。

预训练步骤：数据收集->严格清洗->词元化->切分批次

不可约损失：真实数据分布的熵值

可约损失：真实分布和模型分布之间KL散度的估计

KM扩展法则和Chinchilla扩展法则的总结：

KM扩展法则和Chinchilla使用交叉熵损失来衡量模型性能，两者都指出了在给定算力情况下，参数规模和数据规模的配比程度, **KM模型侧重于把更多训练资源集中于参数规模的增加上**，而**Chinchilla则倾向于两者规模同时增加**（数据规模大概是参数规模的5倍），但越来越多的工作表明，**预训练模型对数据的需求远大于扩展法则给出的数据规模**，如LLaMa-2模型使用了7B的参数规模和2T的词元（数据规模）进行训练。

启示：很多小模型也可以通过使用超大规模预训练数据获得较大的模型性能提升，这种现象的一个重要原因是**Transformer结构具有良好的数据扩展性**。

**扩展法则**使用语言建模损失来衡量模型整体性能，体现了性能提升的**连续性、可预测性**

**涌现能力**使用任务性能来衡量模型整体性能，体现了性能随规模提升的**不连续性, （跳跃性或间断性)、不可预测性。**



***

**本章知识总览：**

* 大语言模型的构建过程
* **扩展法则(Scaling Law)**
* 涌现能力(Emergent Abilities)
* GPT系列模型的研发历程



### 2.1 大语言模型的构建过程

大语言模型的构建可以分为**大规模预训练**和**指令微调与人类对齐**两个阶段

#### 1、大规模预训练

预训练：预训练是指使用与下游任务无关的大规模数据进行模型参数的初始训练，可以认为是为模型参数找到一个较好的“初值点”。

OpenAI前首席科学家Ilya Sutskever指出大规模预训练本质上是在**做一个世界知识的压缩**，**从而能够学习到一个编码世界知识的参数模型**，**模型通过解压缩所需要的知识来解决现实世界的任务**。

GPT系列模型证实了“**解码器+预测下一个词**”这一任务求解范式的有效性，它已经成为现有大语言模型主要采纳的技术路径。

预训练步骤：

* 数据收集：准备大规模文本数据
  * 来源：书籍、网页、代码、对话等
  * 格式：纯文本(txt)、JSON或数据库存储
* 严格清洗: 去除噪声和有毒有害内容
  * 去重：删除重复文档或段落(如MinHash算法)
  * 过滤低质量内容：移除乱码、广告、非目标语言文本
  * 毒性过滤：使用分类模型检测仇恨言论、暴力等非法内容(如Google的Perspective API)
  * 标准化：统一大小写、标点、Unicode编码(如将“é”转为“e”)
* 词元化(Tokenization)
  * 选择词元算法：如BPE(GPT系列)、WordPiece(bert)
  * 训练词表：基于清洗后的数据统计子词频率，生成词表(如50000词元)
  * 编码文本：将文本转化为词元ID序列，即向量化(如```“Hello!"-->[15496,0]``` )
* 切分批次(Batching) 
  * 目标：将词元化后的数据组织为固定长度的训练批次
  * 关键问题：文本长度不一需要统一填充或者截断，高效利用GPU内存，避免内存不足(OOM)

目前开源模型普遍采用2T~3T规模的词元进行预训练，并有进一步扩大的趋势。这对算力要求极高，训练百亿模型需要百卡规模的算力集群(如A100 80G)

**(1) 模型规模与算力关系**

| 模型规模   | 参数量 | 显存需求（训练）      | 推荐硬件配置                 | 训练时间（假设效率100%） |
| :--------- | :----- | :-------------------- | :--------------------------- | :----------------------- |
| **百亿级** | 10B+   | 80GB显存/卡 × 100+卡  | 100×A100 80G NVLink互联      | 2-6个月                  |
| **千亿级** | 100B+  | 80GB显存/卡 × 1000+卡 | 1000×H100 + InfiniBand网络   | 6-12个月                 |
| **万亿级** | 1T+    | 需模型并行+显存优化   | 万卡集群（如Google TPU Pod） | 1年以上                  |

- **显存估算公式**（混合精度训练）：
  $$
  \text{显存(GB)}\approx\frac{\text{参数量}\times(16\mathrm{bit}+8\text{bit梯度})}{8\times1024^3}\times\text{批次大小}
  $$
  
  
  例如：175B参数模型（GPT-3）需约3.5TB显存，需千卡A100联合存储。



### 2.2 扩展法则

#### 1、KM扩展法则

模型规模$\left(N\right)$，数据规模$\left(D\right)$，计算算力$\left(C\right)$之间的幂律关系(Power-Law Relationship)，在给定算力预算c的条件下，近似可以得到以下三个基本指数公式来描述扩展法则:
$$
\begin{array} {l c l} {{{L ( N )}}} & {{{=}}} & {{{\left( \frac{N_{c}} {N} \right)^{\alpha_{N}}, ~ ~ \alpha_{N} \sim0. 0 7 6, N_{c} \sim8. 8 \times1 0^{1 3}}}} \\ {{{L ( D )}}} & {{=}} & {{\left( \frac{D_{c}} {D} \right)^{\alpha_{D}}, ~ ~ \alpha_{D} \sim0. 0 9 5, D_{c} \sim5. 4 \times1 0^{1 3}}} \\ {{{L ( C )}}} & {{=}} & {{\left( \frac{C_{c}} {C} \right)^{\alpha_{C}}, ~ ~ \alpha_{C} \sim0. 0 5 0, C_{c} \sim3. 1 \times1 0^{8}}} \\ \end{array}
$$
$L ( \cdot)$ 表示 . $\mathrm{n a t}$ 为单位的交叉熵损失。其中， $N_{c}$  $D_{c}$ 和 $C_{c}$ 是实验性的常数数值

知识补充：

* **nat ** 是信息熵的自然对数单位，用于交叉熵损失的计算。$nat$ 用来表示以e 为底信息量的自然对数。
* **交叉熵损失**直接反映模型预测与真实数据的差异，是优化目标和性能评估的核心指标。
* 其优势包括：信息论意义明确、与困惑度挂钩、优化梯度友好，且被广泛用于大语言模型的扩展定律（如KM法则）。

为便于理解，OpenAI把损失函数进一步分为两部分：**不可约损失**和**可约损失**

不可约损失是真实数据分布的熵，可约损失是真实分布与模型分布之间的KL散度：
$$
L(x)=\underbrace {L_\infty}_{不可约损失} +\underbrace {\left({\frac {x_0} x}\right)^{\alpha_{x}}}_{可约损失}
$$
这里的$x$是占位符号，可以代指KM扩展法则中的$N、D、C$。其中不可约损失由数据自身特征确定，无法通过扩展法则或者优化算法进行约减；模型性能的优化只能减少可约损失部分。

#### 2、Chinchilla扩展法则

DeepMind团队的Hoffmann等人于2022年提出了一种可选的扩展法则，旨在指导大语言模型充分利用给定的算力资源进行优化训练。通过针对更大范围的模型规模（70M到16B参数）和数据规模 (5B到500B词元) 进行实验，研究人员拟合得到了另一种关于模型性能的幂律关系:
$$
L\left(N,D\right) = E+ \frac{A} {N^\alpha} + \frac B {D^\beta}
$$
其中 $ E=1.69,A=406.4 ,B=410.7,\alpha=0.34,\beta=0.28$. 进一步，利用约束条件$C=6ND$对于损失函数$L(N,D)$进行推导，能够获得算力资源固定情况下模型规模与数据规模最优分配方案：
$$
N_{opt}(C)=G {\left( \frac C 6 \right)}^a,D_{opt}(C)=G^{-1} \left( \frac C 6\right)^b
$$
这里 $a=\frac \alpha {\alpha+\beta},b=\frac \beta {\alpha+\beta}$, $G$ 是由$A、B、a$和$\beta$ 计算得出的扩展系数

进一步，研究人员发现KM扩展法则和Chinchilla扩展法则都可以近似表示成下述所示 
$$
N_{\mathrm{o p t}} \approx C^{a}, D_{\mathrm{o p t}} \approx C^{b},
$$
当给定算力C的情况下，最优模型参数规模和数据规模由指数系数a、b分别确定。a和b决定了参数规模和数据规模的资源分配优先级：当a>b时，应用更多算力去提高参数规模；当b>a时，应用更多算力去提高数据规模。

KM和Chinchilla扩展法则不同之处在于：随着算力预算增加，

KM扩展法则倾向于将更大的预算分配给模型规模增加($a ≈ 0.73, b\approx0.27$)

而Chinchilla扩展法则更主张两种规模参数应该以等比例关系增加($a ≈ 0.46, b\approx0.54$)

Chinchilla扩展法则的研究意义：Chinchilla法则研究的意义不在于给出资源在数据规模与模型规模上的具体分配方案，而是首次指出了之前的预训练工作可能忽视了数据的规模扩展。**让研究人员把重心聚焦于数据的规模扩展上**，如：175B参数的GPT-3仅仅使用了300B的词元进行训练，数据量远远小于模型能够编码的最大数据容量。

在CHInchilla指导下，DeepMind团队训练得到了具有70B参数，1.4T词元的Chinchilla模型。

越来越多工作表明预训练语言模型对于数据需求量远高于扩展法则给出的估计规模，如LLaMA-2(7B)的模型就使用了2T的数据量(词元) 并且很多更小的模型也能通过使用超大规模的预训练数据获得较大的模型性能提升。这其中一个非常重要的原因是Transformer架构具有良好的数据扩展性。

#### 3、扩展法则的讨论

（1）可预测的扩展：通过较小的算力资源可靠地估计较大算力资源的模型性能。

* 可预测性表现的两个方面
  * 使用小模型性能估计大模型性能
  * 使用大模型早期训练性能估计训练完成后的性能
* 可预测的扩展对于模型训练的两个指导作用：
  * 训练小型代理模型来确定大型模型的预训练数据混合最佳比例
  * 针对大语言模型较长训练阶段中的损失波动情况，扩展法则可用于监控大语言模型的训练状态，如在早期识别异常性能
* 扩展法则与实际训练效果的尾部差异：
  * 扩展法则刻画的模型性能增长与投入的指数变化趋势，因此模型会出现随着规模扩展**收益递减**的情况，**训练后期扩展收益增长缓慢甚至停滞**。
  * OpenAI的研究表明，**即使接近不可约的模型损失，模型训练接近递减收益点，模型表征的质量仍然能随着规模扩展而有效提升**，这项研究表明大模型对于改善下游任务性能非常重要。
* 一个潜在问题：随着规模增加，公共文本数据很快“枯竭”，如何在数据受限的情况下建模扩展法则，仍然具有重要的实践意义。在这种情况下，数据重合或者数据合成可能有助于缓解数据稀缺问题。

（2）任务层面的可预测性：扩展法则的研究大多基于语言建模损失开展，如预测下一个词元的平均交叉熵损失，这是对模型整体性能的宏观度量。在实践中则更关注大语言模型在真实任务中的性能提升。

* 整体上来说，语言建模损失较小的模型在下游的任务重表现更好，但对于一些特殊任务，会出现“逆向扩展(Inverse Scaling)”的 现象，即随着语言建模损失降低(理论意义上的性能提升)，实际任务性能却变差。

* 根据GPT-4，利用扩展法则可以准确预测一些任务能力，如编码能力；但对于另一些任务的性能预测非常困难；且有些重要能力如上下文学习能力是扩展法则不可预测的，只有当模型大小超过一定规模上时才会出现，即“涌现能力”

### 2.3 涌现能力

#### 1、三种代表性的涌现能力

* **上下文学习能力**
* **指令遵循能力**：是指大语言模型能够按照自然语言指令来执行对应的任务。
  为了获得这一能力，通常需要使用自然语言描述的多任务示例数据集进行微调，称为指令微调（Instruction Tuning）或监督微调（Supervised Fine-tuning）
  * 相比于上下文学习能力，指令遵循能力整体上更容易获得，但是最终的任务执行效果还取决于模型性能和任务难度决定。
* **逐步推理能力**：大语言模型可以利用思维链提示策略来加强推理性能。大语言模型可以在提示中引入任务相关的中间推理步骤来加强复杂任务的求解。思维链提示可以提高62B和540B 的PaLM模型的算数推理能力，540B参数上的提升更加明细。
  * 思维链提示特别适合帮助大语言模型解决复杂数学问题，思维链能力也是大语言模型能力的重要体现。

#### 2、涌现能力与扩展法则的关系

**扩展法则**使用语言建模损失来衡量模型整体性能，体现了性能提升的**连续性、可预测性**

**涌现能力**使用任务性能来衡量模型整体性能，体现了性能随规模提升的**不连续性, （跳跃性或间断性)、不可预测性。**

扩展法则指数形式暗示着模型性能提升存在边际效益递减的情况，而涌现能力一旦出现则意味着模型性能大幅跃升。

一些研究认为，涌现能力的不连续性是**评估指标的不连续**(如生成代码的准确性使用测试数据通过率评估)和**有限的模型参数规模**(如PaLM技术报告里面只展示了8B, 62B, 540B 三个版本的模型)导致的，如果针对性修改评估指标，提供更为连续的模型尺寸候选，涌现能力曲线的突然跃升可能会消失(变为平滑连续)。但在实际使用中，**用户是以一种“不连续”的方式感知大语言模型的性能优劣**，模型输出正确性更为重要，用户满意度体验本身就是离散的。

**类似马哲量变质变规律，我个人认为：涌现能力类似质变的提升，是大量量的积累后产生的模型性能不连续的跳跃提升。而扩展法则刻画了模型性能量变提升的过程，是连续性和可预测性的体现。**

![](https://s3.bmp.ovh/imgs/2025/04/07/9e982c7a1c1dd4ed.png)

​										大语言模型的发展时间线

### 2.4 GPT系列模型的技术演变

![](https://s3.bmp.ovh/imgs/2025/04/07/7fb6694484b0676d.png)

​							GPT 系列模型技术发展的历程图

* GPT模型的本质

GPT 系列模型的基本原理是训练模型学习恢复预训练文本数据，将广泛的世界知识压缩到仅包含解码器（Decoder-Only）的Transformer 模型中，从而使模型能够学习获得较为全面的能力。

GPT**数学本质**： $ P ( x_{t} | x_{< t})$是自回归语言模型的核心，通过最大化似然估计学习数据的条件概率分布,模型不仅学会"接龙"，还内化了语言结构、常识甚至推理能力，尽管其本质仍是概率预测。

两个关键要素: 训练能够准确预测下一个词的Transformer （只包含解码器）语言模型；（II）扩展语言模型的规模以及扩展预训练数据的规模。

* 发展历程

GPT3基于下面的学习范式(模型训练范式)：大语言模型的训练与利用可以通过语言建模的形式进行统一描述：模型预训练是在给定上下文条件下预测后续文本序列，模型使用则是根据任务描述以及示例数据来推理正确的任务解决方案。

GPT3还建立了以提示学习方法为基础技术路线的任务求解范式。

OpenAI探索了两种主要途径改善GPT3模型：代码数据训练和人类对齐，前者通过提升GPT模型的编程能力和数学解题能力来提升GPT模型的综合性能，后者使GPT模型的输出更符合人类需求，提高指令遵循能力，缓解有害内容生成。

GPT-4首次将GPT模型输入由单一文本模态拓展到图文双模态，在解决复杂任务方面的能力显著强于GPT3.5

GPT-4V在多种场景表现出强大的视觉能力和综合任务解决能力。GPT-4 Turbo提升了模型的整体能力，还引入了新功能如函数调用，可重复输出等。

* 局限

GPT模型会在某些特定上下文中生成带有事实错误的内容（即幻觉）或存在潜在风险的回应。





一些思考：

指令微调(Instruction Tuning)是数据训练过程，不同于预训练庞大的数据规模，其只需要少量的数据就可以显著提升大语言模型在下游任务的模型性能。指令微调会改变模型参数

提示词工程(rompting)

提示词工程的案例：

我在使用大模型比如DeepSeek或chatGPT系列时，我给出问答，它给我答案，当答案不符合预期或不正确时，我可能会把任务拆分成不同步骤，将每一步向大模型提问，当每一步大模型的回答都正确，可以总结得出总体的任务解决方案。

| **你的操作**                | **对应的Prompting技术**        | **作用**                         | **示例（以数学题为例）**         |
| :-------------------------- | :----------------------------- | :------------------------------- | :------------------------------- |
| **直接提问完整问题**        | **零样本提示（Zero-Shot）**    | **测试模型原始能力**             | **"解方程3x+5=20" → 直接给答案** |
| **发现错误后拆分步骤提问**  | **思维链提示（CoT）**          | **暴露模型的推理逻辑，便于纠错** | "先写解方程步骤：1.移项→2.除法…" |
| 对每步结果人工验证/调整提问 | 自洽性校验（Self-Consistency） | 确保每一步正确性，避免错误累积   | 检查“移项是否正确”再继续下一步   |
| 组合正确步骤得出最终答案    | 多步推理整合                   | 综合局部正确结果得到全局解决方案 | 根据正确步骤组合出x=5            |

需要强调是是：提示词工程没有改变模型参数，没有从物理意义上提升模型能力，即没有提升模型的固有能力(固有能力是那些由模型参数决定的本质能力的上限，如：知识面覆盖程度，逻辑推理深度，数学计算精度)。但模型的具体表现能力可通过提示词工程显著提升，例如同一模型的同一任务用零样本提示和思维链提示往往会得到完全不同的答案质量。

在我个人理解里面，指令微调(Instruction Tuning)提高了模型的
