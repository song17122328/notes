前两篇论文针对LLM推理优化：

**DistServe**将模型推理的预填充与解码分离，将预填充应用于独立的GPU组(A100)，解码应用于独立的GPU组（H100）

预填充属于计算密集型，可以使用张量并行(模型并行的子类)，加快计算

解码(IO密集型)使用流水线并行策略。

预填充完成后生成的KV Cache直接通过NVlink转移到解码GPU组。

<img src="https://cdn.jsdelivr.net/gh/song17122328/MyPic@main/img/image-20250501142303057.png" alt="DistServe架构图" style="zoom: 67%;" />





**Orac**核心技术：迭代级调度，选择性批处理，层间调度和层内调度
迭代级别调度：将云端模型推理过程中的请求批处理拆分成迭代批处理。将原来的将一批请求放到GPU里面并行计算转变化将一个请求拆分为不同的迭代(迭代可以理解为生成一个token，也即一个解码过程)。通过配置并行处理不同请求的不同迭代过程，避免了短请求等长请求的现象，减少了系统延迟，增加了模型推理的并行程度。

**选择性批处理**：对除了Attention层的其他层如FC（全连接层）、layerNorm(层增正则化)进行批处理

对Attention层不进行批处理，而是按照每个请求单独处理。

这是因为批处理需要每个处理单元的shape一致，而Attention层需要看每个处理单元之前的token，不能保证shape一致 (不同的请求有不同的前序token，即KV缓存)。

迭代级调度图(图4)：

<img src="https://cdn.jsdelivr.net/gh/song17122328/MyPic@main/img/image-20250501142853978.png" alt="Orca简要结构图" style="zoom:50%;" />

选择性批处理(图5)

<img src="https://cdn.jsdelivr.net/gh/song17122328/MyPic@main/img/image-20250501144213318.png" alt="image-20250501144213318" style="zoom:50%;" />

不同并行策略分析(图6和图7)：

<img src="https://cdn.jsdelivr.net/gh/song17122328/MyPic@main/img/image-20250501145755529.png" alt="image-20250501145755529" style="zoom: 67%;" />





后两篇论文：PartialLoading和Hermes聚焦在边缘设备的模型加载和模型推理上。

PartialLoading关注点放在同一边缘服务器，不同模型(不是大模型)切换开销，通过底部层参数共享来最优化用户请求调度，通过对指定用户调度的资源带宽配置来最大化用户吞吐量。

![PartialLoading框架图](https://cdn.jsdelivr.net/gh/song17122328/MyPic@main/img/image-20250501141731008.png)

Hermes关注点放在许多边缘设备共同服务一个大模型,通过并行加载减少模型加载延迟，通过动态内存管理减少内存消耗。

![Heremes框架图](https://cdn.jsdelivr.net/gh/song17122328/MyPic@main/img/image-20250501141852157.png)

![Herems:PipeLoad机制](https://cdn.jsdelivr.net/gh/song17122328/MyPic@main/img/image-20250501141939598.png)

Collaborative Edge computing （Edge shard) 则是把大模型切块，分配到不同的边缘设备中，使得分散的边缘设备能运行大模型

![image-20250501141441435](https://cdn.jsdelivr.net/gh/song17122328/MyPic@main/img/image-20250501141441435.png)

