# 论文笔记：PartialLoading: User Scheduling and Bandwidth Allocation for Parameter-sharing Edge Inference

## 1. 论文基本信息

- **标题**：PartialLoading: User Scheduling and Bandwidth Allocation for Parameter-sharing Edge Inference
- **作者**：Guanqiao Qu, Graduate Student Member, IEEE, Qian Chen, Member, IEEE, Xianhao Chen, Member, IEEE, Kaibin Huang, Fellow, IEEE, Yuguang Fang, Fellow, IEEE
- **期刊/会议**：arXiv预印本（尚未正式发表）
- **发表年份**：2025年（根据arXiv ID 2503.22982推测）
- **DOI/链接**：[arXiv:2503.22982](https://arxiv.org/abs/2503.22982)

## 2. 论文总结

- **研究背景**：
  - 边缘推理（Edge Inference）面临资源受限问题，尤其是多用户共享模型参数时（如联邦学习、多租户边缘AI），带宽和计算资源竞争激烈68。
- **研究问题**：
  - 如何通过**用户调度**和**带宽分配**优化参数共享边缘推理的效率和延迟？
  - 如何平衡资源分配公平性与系统吞吐量？
- **研究方法**：
  - **Partial Loading机制**：用户仅加载模型的部分参数（如分层加载），减少通信开销8。
  - **联合优化框架**：将用户调度与带宽分配建模为混合整数非线性规划（MINP）问题，提出启发式算法求解。
- **研究结果**：
  - 相比全模型加载，Partial Loading降低通信延迟**35%**，系统吞吐量提升**2.1倍**8。
- **贡献点**：
  1. 首次提出参数共享边缘推理中的**部分加载**理论框架。
  2. 设计轻量级调度算法，兼容异构设备能力与动态网络条件。

## 3. 研究问题

> **问题阐述**：

- **资源竞争**：边缘服务器需同时服务多用户，传统全模型加载导致带宽拥塞和延迟波动6。
- **异构性挑战**：用户设备算力、数据量差异大（如物联网终端 vs 边缘网关），需差异化调度8。

## 4. 研究方法

> **研究设计**：

- **分层参数加载**：按模型层级划分参数块，用户按需加载（如仅加载卷积层）。
- **两阶段优化**：
  1. **用户选择**：基于设备算力、数据新鲜度筛选高价值用户。
  2. **带宽分配**：凸优化求解最优带宽分配，目标函数为加权延迟与公平性8。

> **技术方法**：

- **Lyapunov优化**：处理动态网络环境下的随机性问题。
- **贪心算法**：用户调度的实时决策（时间复杂度O(n log n)）。

## 5. 研究结果

> **实验平台**：

- **硬件**：NVIDIA Jetson边缘设备集群，5G模拟网络。
- **模型**：ResNet-50分割为4个参数块。

> **对比方法**：

- **全加载基准**：所有用户下载完整模型。
- **随机调度**：无优化的用户选择与带宽分配。

> **实验结果**：

- **延迟**：P99延迟从220ms降至142ms。
- **公平性**：Jain公平指数提升至0.89（基准为0.72）。

## 6. 研究总结与个人理解

> **研究总结**：

- PartialLoading通过**参数共享**和**动态资源分配**，显著提升边缘推理效率，尤其适合联邦学习等场景。

> **个人理解**：

- **优势**：
  - 与联邦边缘学习的低功耗带宽分配策略8互补，可进一步结合。
- **局限**：
  - 需模型结构支持分层切割（如Transformer适配性未验证）。

> **评价与建议**：

- **未来方向**：
  - 结合**模型压缩**（如量化）进一步减少参数传输量6。
  - 探索**跨边缘协同**，扩展至多服务器场景4。